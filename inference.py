"""Script d'inf√©rence pour le projet Exoplanet.

Charge un checkpoint (par d√©faut : `checkpoints/exoplanet_modelbest.pth`) et
pr√©dit la sortie pour un exemple choisi dans les fichiers de donn√©es.

Usage:
    python inference.py --checkpoint checkpoints/exoplanet_modelbest.pth --index 0
    
ex : 
python inference.py   --checkpoint checkpoints/exoplanet_modelbest.pth   --spectra D√©fi-IA-2026/DATA/defi-ia-cnes/spectra.npy   --auxiliary D√©fi-IA-2026/DATA/defi-ia-cnes/auxiliary.csv   --targets D√©fi-IA-2026/DATA/defi-ia-cnes/targets.csv   --index 54   --verbose

Options:
    --checkpoint : chemin vers le fichier .pth
    --spectra    : chemin vers le fichier .npy de spectres
    --auxiliary  : chemin vers le fichier .csv auxiliaire
    --targets    : chemin vers le fichier .csv des targets (optionnel, pour comparaison)
    --index      : index de l'exemple √† pr√©dire (d√©faut 0)
    --device     : cpu ou cuda
"""
import argparse
import json
import os
from pathlib import Path

import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F

# Importer les classes de mod√®les et le dataset
from models.CNN import CNN
from models.ResNetCNN import ResNet1D
from models.dataset import ExoplanetDataset, collate_fn

def remove_module_prefix(state_dict: dict) -> dict:
    """Retire le pr√©fixe 'module.' si pr√©sent (sauvegarde DataParallel)."""
    new_state = {}
    for k, v in state_dict.items():
        new_key = k
        if k.startswith('module.'):
            new_key = k[len('module.'):]
        new_state[new_key] = v
    return new_state

def detect_model_class(state_dict: dict) -> str:
    """Detecte la famille de mod√®le √† partir des cl√©s du state dict."""
    keys = list(state_dict.keys())
    if any(k.startswith('stem.0.') or k.startswith('stem.0') for k in keys):
        return 'resnet'
    if any(k.startswith('conv_layers.0.0.') or k.startswith('conv_layers.0.0') for k in keys):
        return 'cnn'
    # fallback
    return 'cnn'

def load_checkpoint(checkpoint_path: str, device: str = 'cpu') -> dict:
    """Charge un checkpoint PyTorch de mani√®re compatible."""
    try:
        # Tentative avec weights_only=True (mode s√©curis√©)
        import torch.serialization
        # Utiliser numpy._core au lieu de numpy.core (nouvelle API)
        try:
            from numpy._core.multiarray import scalar as np_scalar
        except ImportError:
            from numpy.core.multiarray import scalar as np_scalar

        torch.serialization.add_safe_globals([np_scalar])
        checkpoint = torch.load(checkpoint_path, map_location=device)
    except Exception as e:
        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    return checkpoint

def main():
    parser = argparse.ArgumentParser(description='Inference script')
    parser.add_argument('--checkpoint', type=str, default='checkpoints/exoplanet_modelbest.pth')
    parser.add_argument('--spectra', type=str, default='D√©fi-IA-2026/DATA/defi-ia-cnes/spectra_test.npy')
    parser.add_argument('--auxiliary', type=str, default='D√©fi-IA-2026/DATA/defi-ia-cnes/auxiliary_test.csv')
    parser.add_argument('--targets', type=str, default=None, help='Fichier targets.csv pour comparaison (optionnel)')
    parser.add_argument('--index', type=int, default=0)
    parser.add_argument('--device', type=str, default='cpu')
    parser.add_argument('--threshold', type=float, default=0.5)
    parser.add_argument('--save', type=str, default=None, help='Fichier JSON de sortie (optionnel)')
    parser.add_argument('--verbose', action='store_true', help='Affichage d√©taill√©')

    args = parser.parse_args()

    device = torch.device(args.device if torch.cuda.is_available() and args.device.startswith('cuda') else 'cpu')

    print('\n' + '='*60)
    print('üî¨ SCRIPT D\'INF√âRENCE - EXOPLANET')
    print('='*60)
    print(f"üìÅ Checkpoint: {args.checkpoint}")
    print(f"üíª Device: {device}")
    print(f"üéØ Index: {args.index}")
    print(f"üìä Seuil: {args.threshold}")
    print('='*60)

    # V√©rifications des fichiers
    ckpt_path = Path(args.checkpoint)
    if not ckpt_path.exists():
        raise FileNotFoundError(f"Checkpoint introuvable: {ckpt_path}")

    if not Path(args.spectra).exists():
        raise FileNotFoundError(f"Fichier spectra introuvable: {args.spectra}")
    if not Path(args.auxiliary).exists():
        raise FileNotFoundError(f"Fichier auxiliary introuvable: {args.auxiliary}")

    # V√©rifier si on a un fichier targets pour la comparaison
    has_targets = args.targets is not None and Path(args.targets).exists()

    # Charger les donn√©es (on utilisera ExoplanetDataset pour les m√™mes normalisations)
    print("\nüì• Chargement des donn√©es...")
    dataset = ExoplanetDataset(
        spectra_path=args.spectra,
        auxiliary_path=args.auxiliary,
        targets_path=args.targets if has_targets else None,
        is_train=False
    )

    if args.index < 0 or args.index >= len(dataset):
        raise IndexError(f"Index hors limites: {args.index} (0..{len(dataset)-1})")

    sample = dataset[args.index]

    # Pr√©parer un batch de taille 1
    spectrum = sample['spectrum'].unsqueeze(0)  # (1, 52, 3)
    # Transposer vers (batch, channels, length)
    spectrum = spectrum.permute(0, 2, 1).to(device)
    auxiliary = sample['auxiliary'].unsqueeze(0).to(device)

    # R√©cup√©rer les vraies valeurs si disponibles
    true_targets = None
    if has_targets and 'target' in sample:
        true_targets = sample['target'].cpu().numpy()  # [eau, nuage]

    checkpoint = load_checkpoint(str(ckpt_path), device=str(device))

    state_dict = checkpoint.get('model_state_dict', None)
    if state_dict is None:
        # Peut-√™tre le checkpoint est le state_dict directement
        state_dict = checkpoint

    # D√©tecter type de mod√®le
    state_dict = remove_module_prefix(state_dict)
    model_type = detect_model_class(state_dict)
    print(f"   ‚Ä¢ Type de mod√®le d√©tect√©: {model_type.upper()}")

    # Inf√©rer param√®tres √† partir des donn√©es
    _, channels, length = spectrum.shape  # (B, C, L)
    auxiliary_dim = auxiliary.shape[1]

    if model_type == 'ResNet':
        model = ResNet1D(
            spectrum_length=length,
            auxiliary_dim=auxiliary_dim,
            num_classes=2,
            augmentation_factor=10, 
            shift_range=0.05,
            scale_range=0.1
        )
    else:
        # CNN classique
        model = CNN(
            spectrum_length=length,
            auxiliary_dim=auxiliary_dim,
            num_classes=2,
            input_channels=channels
        )

    # Charger les poids
    try:
        model.load_state_dict(state_dict)
    except RuntimeError:
        # Tentative moins stricte: some keys may differ (ex: ancien mod√®le) ‚Üí load partiel
        model.load_state_dict(state_dict, strict=False)

    model = model.to(device)
    model.eval()

    # Compter les param√®tres
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    with torch.no_grad():
        logits = model(spectrum, auxiliary)  # (1, num_classes)
        probs = torch.sigmoid(logits).cpu().numpy().squeeze(0)

    preds = [1 if p >= args.threshold else 0 for p in probs]

    result = {
        'checkpoint': str(ckpt_path),
        'model_type': model_type,
        'index': args.index,
        'threshold': args.threshold,
        'logits': {
            'eau': float(logits[0, 0].cpu().item()),
            'nuage': float(logits[0, 1].cpu().item())
        },
        'probabilities': {
            'eau': float(probs[0]),
            'nuage': float(probs[1])
        },
        'predictions': {
            'eau': bool(preds[0]),
            'nuage': bool(preds[1])
        }
    }

    # Ajouter la comparaison avec la v√©rit√© terrain si disponible
    if true_targets is not None:
        true_eau = int(true_targets[0])
        true_nuage = int(true_targets[1])

        result['ground_truth'] = {
            'eau': bool(true_eau),
            'nuage': bool(true_nuage)
        }

        result['evaluation'] = {
            'eau': {
                'correct': bool(preds[0] == true_eau),
                'status': ' CORRECT' if preds[0] == true_eau else '‚ùå INCORRECT'
            },
            'nuage': {
                'correct': bool(preds[1] == true_nuage),
                'status': ' CORRECT' if preds[1] == true_nuage else '‚ùå INCORRECT'
            },
            'both_correct': bool(preds[0] == true_eau and preds[1] == true_nuage)
        }

    print('\n' + '='*60)
    print(' R√âSULTAT D\'INF√âRENCE')
    print('='*60)
    print(json.dumps(result, indent=2, ensure_ascii=False))

    # Affichage visuel am√©lior√©
    print('\n' + '='*60)
    print(' PR√âDICTIONS D√âTAILL√âES')
    print('='*60)
    
    print(f"\n EAU:")
    print(f"   Logit:        {result['logits']['eau']:+.4f}")
    print(f"   Probabilit√©:  {result['probabilities']['eau']:.6f} ({result['probabilities']['eau']*100:.4f}%)")
    print(f"   Pr√©diction:   {' PR√âSENTE' if preds[0] else '‚ùå ABSENTE'}")
    
    print(f"\n  NUAGES:")
    print(f"   Logit:        {result['logits']['nuage']:+.4f}")
    print(f"   Probabilit√©:  {result['probabilities']['nuage']:.6f} ({result['probabilities']['nuage']*100:.4f}%)")
    print(f"   Pr√©diction:   {' PR√âSENTS' if preds[1] else '‚ùå ABSENTS'}")

    if true_targets is not None:
        print('\n' + '='*60)
        print(' COMPARAISON PR√âDICTIONS vs V√âRIT√â TERRAIN')
        print('='*60)

        print(f"\n EAU:")
        print(f"   Pr√©diction: {preds[0]} (probabilit√©: {probs[0]:.6f})")
        print(f"   V√©rit√©:     {true_eau}")
        print(f"   R√©sultat:   {result['evaluation']['eau']['status']}")

        print(f"\n  NUAGES:")
        print(f"   Pr√©diction: {preds[1]} (probabilit√©: {probs[1]:.6f})")
        print(f"   V√©rit√©:     {true_nuage}")
        print(f"   R√©sultat:   {result['evaluation']['nuage']['status']}")

        print(f"\n{'='*60}")
        if result['evaluation']['both_correct']:
            print(" SUCC√àS TOTAL : Les deux pr√©dictions sont correctes!")
        else:
            correct_count = sum([result['evaluation']['eau']['correct'], 
                               result['evaluation']['nuage']['correct']])
            print(f" SUCC√àS PARTIEL : {correct_count}/2 pr√©dictions correctes")
        print('='*60)
    else:
        print('\n' + '='*60)
        print('‚Ñπ  Pas de v√©rit√© terrain disponible pour comparaison')
        print('='*60)

    if args.save:
        with open(args.save, 'w') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"\n R√©sultat sauvegard√© dans {args.save}")

if __name__ == '__main__':
    main()